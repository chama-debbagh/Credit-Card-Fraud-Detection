# Credit-Card-Fraud-Detection
# ğŸ’³ DÃ©tection de Fraude Bancaire avec Machine Learning

Projet rÃ©alisÃ© dans le cadre dâ€™un apprentissage de Data Science. Lâ€™objectif est de dÃ©tecter automatiquement les transactions frauduleuses Ã  lâ€™aide de modÃ¨les supervisÃ©s de classification.

---

## ğŸ“‚ Dataset

- Source : [Kaggle â€“ Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)
- 284 807 transactions
- 30 features PCA (anonymisÃ©es) + montant (`Amount`) + cible (`Class`)
- DonnÃ©es fortement dÃ©sÃ©quilibrÃ©es : 0 = normal, 1 = fraude

---

## âš™ï¸ MÃ©thodologie

- Nettoyage et normalisation (`StandardScaler`)
- Suppression de la colonne `Time`
- Ã‰quilibrage des classes avec **SMOTE**
- SÃ©paration train/test avec **stratification**
- EntraÃ®nement de 3 modÃ¨les :
  - RÃ©gression Logistique
  - Random Forest
  - XGBoost
- Ã‰valuation : `Precision`, `Recall`, `F1-score`, `ROC AUC`

---

## ğŸ¤– ModÃ¨les et RÃ©sultats

| ModÃ¨le             | Recall (fraude) | Precision (fraude) | F1-score | ROC AUC |
|--------------------|------------------|---------------------|----------|---------|
| LogisticRegression | 0.92             | 0.06                | 0.11     | 0.9459  |
| RandomForest       | ...              | ...                 | ...      | ...     |
| XGBoost            | 0.90             | 0.20                | 0.32     | 0.9458  |

> XGBoost donne le meilleur compromis entre rappel et prÃ©cision.

---

## ğŸ“ˆ Exemple de visualisations

- Distribution des montants
- RÃ©partition des classes
- Matrice de confusion
- Importance des variables

---

## ğŸ› ï¸ Stack technique

- Python
- Pandas, NumPy
- Scikit-learn
- imbalanced-learn (SMOTE)
- XGBoost
- Seaborn, Matplotlib

---

## ğŸ“ Structure du projet
---

## ğŸ§  Auteur

Chama Debbagh  
Ã‰tudiante en Data Science â€“ Juin 2025  
Projet Ã  fort impact mÃ©tier, appliquÃ© Ã  un contexte rÃ©el (assurances/banques)


